{"type": "root", "attrs": {"type": "node", "context": "sop", "internal": "labs::av_structure_from_motion::6.0", "icon": "alicevision.png", "tags": "sidefxlabs,  photogrammetry", "version": "6.0", "namespace": "labs"}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Labs AV Structure from Motion"], "extent": [0, 34]}, {"type": "summary", "indent": 0, "text": [" Detects 3D points with position and orientation and calibrate the cameras accordingly using Alicevision. "], "extent": [167, 281]}, {"type": "para", "indent": 0, "text": ["The objective of this step is to understand the geometric relationship behind all the observations provided by the input images, and infer the rigid scene structure (3D points) with the pose (position and orientation) and internal calibration of all cameras. The output of this node will be a point cloud."], "extent": [281, 588]}, {"type": "note_group", "body": [{"type": "note", "indent": 0, "role": "item", "extent": [588, 594], "body": [{"type": "para", "indent": 4, "text": ["Requires Meshroom/AliceVision version 2023.3.0. See ", {"scheme": null, "value": "https://alicevision.org/#meshroom", "type": "link", "text": ["https://alicevision.org/#meshroom"], "exists": true}, " for information on how to download."], "extent": [594, 757]}], "container": true}], "container": true, "role": "item_group"}, {"level": 1, "id": "parameters", "container": true, "type": "parameters_section", "indent": 0, "role": "section", "extent": [757, 769], "body": [{"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Main"], "extent": [769, 784], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Cook"], "extent": [784, 794], "body": [{"type": "para", "indent": 8, "text": ["Start the cooking process for this step."], "extent": [794, 843]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Use Log"], "extent": [843, 856], "body": [{"type": "para", "indent": 8, "text": ["This toggle controls if the status of the current node should be printed to the console. This is useful for getting a quick overview of the progress."], "extent": [856, 1014]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Structure From Motion"], "extent": [1014, 1046], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Describer Types"], "extent": [1046, 1067], "body": [{"type": "para", "indent": 8, "text": ["Describer types used to describe an image."], "extent": [1067, 1118]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Localizer Estimator"], "extent": [1118, 1143], "body": [{"type": "para", "indent": 8, "text": ["Estimator type used to localize cameras (acransac, ransac, lsmeds, loransac, maxconsensus)."], "extent": [1143, 1243]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Num of Matches"], "extent": [1243, 1267], "body": [{"type": "para", "indent": 8, "text": ["Maximum number of matches per image pair (and per feature type).\n        This can be useful to have a quick reconstruction overview. 0 means no limit."], "extent": [1267, 1426]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Inter File Extension"], "extent": [1426, 1452], "body": [{"type": "para", "indent": 8, "text": ["Extension of the intermediate file export."], "extent": [1452, 1503]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Number of Images"], "extent": [1503, 1529], "body": [{"type": "para", "indent": 8, "text": ["Minimal number of images to use the vocabulary tree. If we have less features than this threshold, we will compute all matching combinations."], "extent": [1529, 1679]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Descriptors"], "extent": [1679, 1700], "body": [{"type": "para", "indent": 8, "text": ["Limit the number of descriptors you load per image. Zero means no limit."], "extent": [1700, 1781]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Number of Matches"], "extent": [1781, 1804], "body": [{"type": "para", "indent": 8, "text": ["The number of matches to retrieve for each image (If 0 it will retrieve all the matches)."], "extent": [1804, 1902]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Lock Scene Previously Reconstructed"], "extent": [1902, 1943], "body": [{"type": "para", "indent": 8, "text": ["This option is useful for SfM augmentation. Lock previously reconstructed poses and intrinsics."], "extent": [1943, 2047]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Observation Constraint"], "extent": [2047, 2075], "body": [{"type": "para", "indent": 8, "text": ["Observation contraint mode used in the optimization:"], "extent": [2075, 2136]}, {"type": "bullet_group", "body": [{"blevel": 10, "type": "bullet", "indent": 8, "text": ["Basic: Use standard reprojection error in pixel coordinates"], "extent": [2136, 2206]}, {"blevel": 10, "type": "bullet", "indent": 8, "text": ["Scale: Use reprojection error in pixel coordinates but relative to the feature scale"], "extent": [2206, 2301]}], "container": true}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Local Bundle Adjustment"], "extent": [2301, 2330], "body": [{"type": "para", "indent": 8, "text": ["It reduces the reconstruction time, especially for large datasets (500+ images), by avoiding computation of the Bundle Adjustment on areas that are not changing."], "extent": [2330, 2500]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Use Only Inputfolder Matches"], "extent": [2500, 2534], "body": [{"type": "para", "indent": 8, "text": ["Use only matches from the input matchesFolder parameter. Matches folders previously added to the SfMData file will be ignored."], "extent": [2534, 2669]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Force Lock of All Intrinsic Camera Parameters"], "extent": [2669, 2720], "body": [{"type": "para", "indent": 8, "text": ["Force to keep constant all the intrinsics parameters of the cameras (focal length, principal point, distortion if any) during the reconstruction. This may be helpful if the input cameras are already fully calibrated."], "extent": [2720, 2945]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Use Rig Constraint"], "extent": [2945, 2969], "body": [{"type": "para", "indent": 8, "text": ["Enable/Disable rig constraint."], "extent": [2969, 3008]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Localizer Max Ransac Iterations"], "extent": [3008, 3045], "body": [{"type": "para", "indent": 8, "text": ["Maximum number of iterations allowed in ransac step."], "extent": [3045, 3106]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["LocalBA Graph Distance"], "extent": [3106, 3134], "body": [{"type": "para", "indent": 8, "text": ["Graph-distance limit to define the Active region in the Local Bundle Adjustment strategy."], "extent": [3134, 3232]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Input Track Length"], "extent": [3232, 3260], "body": [{"type": "para", "indent": 8, "text": ["Minimum track length in input of SfM."], "extent": [3260, 3306]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Observation for Triangulation"], "extent": [3306, 3345], "body": [{"type": "para", "indent": 8, "text": ["Minimum number of observations to triangulate a point. Set it to 3 (or more) reduces drastically the noise in the point cloud, but the number of final poses is a little bit reduced (from 1.5% to 11% on the tested datasets)."], "extent": [3345, 3577]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Angle for Triangulation"], "extent": [3577, 3610], "body": [{"type": "para", "indent": 8, "text": ["Minimum angle for triangulation."], "extent": [3610, 3651]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Localizer Max Ransac Error"], "extent": [3651, 3683], "body": [{"type": "para", "indent": 8, "text": ["Maximum error (in pixels) allowed for camera localization (resectioning). If set to 0, it will select a threshold according to the localizer estimator used (if ACRansac, it will analyze the input data to select the optimal value)."], "extent": [3683, 3922]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Angle for Landmark"], "extent": [3922, 3950], "body": [{"type": "para", "indent": 8, "text": ["Minimum angle for landmark."], "extent": [3950, 3986]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Reprojection Error"], "extent": [3986, 4014], "body": [{"type": "para", "indent": 8, "text": ["Maximum reprojection error."], "extent": [4014, 4050]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Min Angle Initial Pair"], "extent": [4050, 4078], "body": [{"type": "para", "indent": 8, "text": ["Minimum angle for the initial pair."], "extent": [4078, 4122]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Angle Initial Pair"], "extent": [4122, 4150], "body": [{"type": "para", "indent": 8, "text": ["Maximum angle for the initial pair."], "extent": [4150, 4194]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Prepare Dense Scene"], "extent": [4194, 4224], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Output File Type"], "extent": [4224, 4246], "body": [{"type": "para", "indent": 8, "text": ["Output file type for the undistorted images."], "extent": [4246, 4299]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Save Metadata"], "extent": [4299, 4318], "body": [{"type": "para", "indent": 8, "text": ["Save projections and intrinsics information in images metadata (only for .exr images)."], "extent": [4318, 4413]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Save Matrices Text Files"], "extent": [4413, 4443], "body": [{"type": "para", "indent": 8, "text": ["Save projections and intrinsics information in text files."], "extent": [4443, 4510]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Correct images exposure"], "extent": [4510, 4539], "body": [{"type": "para", "indent": 8, "text": ["Apply a correction on images Exposure Value."], "extent": [4539, 4593]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Environment"], "extent": [4593, 4615], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 5, "text": ["Environment"], "extent": [4615, 4633], "body": [{"type": "para", "indent": 8, "text": ["The environment used for launching the AliceVision utilities command line. Note that this is a python expression and should be modified only through ", {"type": "q", "text": ["Edit Expression"]}, "."], "extent": [4633, 4811]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}], "text": "Parameters"}, {"level": 1, "id": "outputs", "container": true, "type": "outputs_section", "indent": 0, "role": "section", "extent": [4811, 4820], "body": [{"type": "dt_group", "body": [{"type": "dt", "indent": 0, "text": ["AV Depth Map"], "extent": [4820, 4834], "body": [{"type": "para", "indent": 4, "text": ["This plugs into AV Depth Map"], "extent": [4834, 4867]}], "container": true}, {"type": "dt", "indent": 0, "text": ["Pointcloud"], "extent": [4867, 4879], "body": [{"type": "para", "indent": 4, "text": ["This is the point cloud generated by the Prepare Dense Scene step."], "extent": [4879, 4952]}], "container": true}], "container": true}], "text": "Outputs"}, {"level": 1, "id": "examples", "container": true, "type": "examples_section", "indent": 0, "role": "section", "extent": [4952, 4962], "body": [{"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": [{"scheme": null, "value": "https://github.com/sideeffects/SideFXLabs/blob/Development/hip/examples/alicevision", "type": "link", "text": ["Example File"], "exists": true}], "extent": [4962, 5067]}], "container": true}], "text": "Examples"}], "title": ["Labs AV Structure from Motion"], "summary": [" Detects 3D points with position and orientation and calibrate the cameras accordingly using Alicevision. "]}